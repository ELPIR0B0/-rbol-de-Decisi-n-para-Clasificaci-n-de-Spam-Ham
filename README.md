# Ãrbol de DecisiÃ³n para ClasificaciÃ³n de Spam/Ham

Este repositorio contiene un experimento de *Machine Learning* basado en **Ã¡rboles de decisiÃ³n** para clasificar correos electrÃ³nicos en dos categorÃ­as: **spam** y **ham** (no spam). El flujo incluye preprocesamiento, entrenamiento/validaciÃ³n repetida, evaluaciÃ³n con mÃ©tricas y visualizaciÃ³n de resultados.

## ğŸ§  Objetivo
Evaluar el desempeÃ±o y la *estabilidad* de un clasificador tipo Ã¡rbol de decisiÃ³n a lo largo de mÃºltiples ejecuciones con particiones estratificadas, reportando **Accuracy**, **F1-score** y sus **Z-scores** normalizados.

## ğŸ“‚ Estructura sugerida del proyecto
```
.
â”œâ”€â”€ ArbolDecisionLeny.py               # Script principal (entrenamiento + grÃ¡ficos)
â”œâ”€â”€ data/
â”‚   â””â”€â”€ dataset_spam_ham.csv          # Dataset (no incluido en el repo)
â””â”€â”€ README.md
```

> **Nota**: AsegÃºrate de que la ruta del dataset en el script apunte a `data/dataset_spam_ham.csv` (o a la ubicaciÃ³n correcta en tu equipo).

## ğŸ“¦ Requisitos
- Python 3.9+
- Paquetes: `pandas`, `numpy`, `matplotlib`, `scikit-learn`, `scipy`

InstalaciÃ³n rÃ¡pida de dependencias:
```bash
pip install pandas numpy matplotlib scikit-learn scipy
```

## ğŸš€ CÃ³mo ejecutar
1. Coloca el archivo `dataset_spam_ham.csv` dentro de la carpeta `data/` (o ajusta la ruta en el script).
2. Ejecuta el script principal:
   ```bash
   python ArbolDecisionLeny.py
   ```
3. El script realiza **50 ejecuciones** con *train/test split* estratificado, entrena un `DecisionTreeClassifier` y genera **tres grÃ¡ficos**:
   - Accuracy por ejecuciÃ³n
   - F1-score por ejecuciÃ³n
   - Z-scores (Accuracy y F1 normalizados)
   
   AdemÃ¡s, imprime en consola un **resumen numÃ©rico** con media y desviaciÃ³n estÃ¡ndar de las mÃ©tricas.

## ğŸ—ƒï¸ Dataset (campos tÃ­picos)
El dataset incluye caracterÃ­sticas de correo como: longitud del mensaje, nÃºmero de enlaces/adjuntos, porcentaje de mayÃºsculas, presencia de HTML, remitente conocido, paÃ­s de origen (codificado *one-hot*), entre otras. Las etiquetas se transforman a binario (`spam=1`, `ham=0`).

## ğŸ“Š Resultados de referencia
En pruebas documentadas, se observaron resultados promedio cercanos a:
- **Accuracy** â‰ˆ 0.9355
- **F1-score** â‰ˆ 0.9503

> Estos valores son **de referencia** y variarÃ¡n segÃºn el dataset y la semilla/particiÃ³n de entrenamiento.

## ğŸ§© Detalles del pipeline
- Limpieza/normalizaciÃ³n de etiqueta (`spam/ham` â†’ binario).
- CodificaciÃ³n *one-hot* para variables categÃ³ricas (`PaisOrigen`, etc.).
- 50 corridas independientes con `train_test_split(..., stratify=y)`.
- Entrenamiento con `DecisionTreeClassifier` (una semilla distinta por corrida).
- CÃ¡lculo de mÃ©tricas `accuracy` y `f1`; normalizaciÃ³n mediante `scipy.stats.zscore`.
- VisualizaciÃ³n con `matplotlib` (3 figuras).
- Resumen final con **medias** y **desviaciones estÃ¡ndar** de las mÃ©tricas.

## ğŸ§ª Reproducibilidad
Para garantizar resultados reproducibles, el script establece una **semilla (`random_state`) diferente** por ejecuciÃ³n, y utiliza divisiÃ³n **estratificada** para preservar la proporciÃ³n de clases en train/test.

## ğŸ› ï¸ Consejos / TODOs
- [ ] Parametrizar la ruta del dataset vÃ­a CLI (`argparse`) en lugar de ruta fija.
- [ ] Guardar las figuras y el resumen numÃ©rico como archivos (`.png`, `.csv`) dentro de una carpeta `outputs/`.
- [ ] AÃ±adir validaciÃ³n cruzada y/o bÃºsqueda de hiperparÃ¡metros.
- [ ] Comparar contra otros modelos (RegresiÃ³n LogÃ­stica, RandomForest, etc.).

## ğŸ‘¤ AutorÃ­a
Trabajo/documentaciÃ³n por **Leny Santiago LÃ³pez Cruz** (ver informe adjunto en el repositorio si aplica).

## ğŸ“„ Licencia
Este proyecto se distribuye bajo licencia **MIT** (puedes modificarla segÃºn tus necesidades).

---

Si necesitas que adapte el script para aceptar argumentos de lÃ­nea de comandos (por ejemplo, `--data data/dataset_spam_ham.csv`), indÃ­calo y lo actualizo en el repositorio.
