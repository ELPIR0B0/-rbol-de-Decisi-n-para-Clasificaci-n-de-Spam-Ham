# √Årbol de Decisi√≥n para Clasificaci√≥n de Spam/Ham

Este repositorio contiene un experimento de *Machine Learning* basado en **√°rboles de decisi√≥n** para clasificar correos electr√≥nicos en dos categor√≠as: **spam** y **ham** (no spam). El flujo incluye preprocesamiento, entrenamiento/validaci√≥n repetida, evaluaci√≥n con m√©tricas y visualizaci√≥n de resultados.

## Objetivo
Evaluar el desempe√±o y la *estabilidad* de un clasificador tipo √°rbol de decisi√≥n a lo largo de m√∫ltiples ejecuciones con particiones estratificadas, reportando **Accuracy**, **F1-score** y sus **Z-scores** normalizados.

## Estructura sugerida del proyecto
```
.
‚îú‚îÄ‚îÄ ArbolDecisionLeny.py               # Script principal (entrenamiento + gr√°ficos)
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ dataset_spam_ham.csv          # Dataset (no incluido en el repo)
‚îî‚îÄ‚îÄ README.md
```

> **Nota**: Aseg√∫rate de que la ruta del dataset en el script apunte a `data/dataset_spam_ham.csv` (o a la ubicaci√≥n correcta en tu equipo).

## Requisitos
- Python 3.9+
- Paquetes: `pandas`, `numpy`, `matplotlib`, `scikit-learn`, `scipy`

Instalaci√≥n r√°pida de dependencias:
```bash
pip install pandas numpy matplotlib scikit-learn scipy
```

## C√≥mo ejecutar
1. Coloca el archivo `dataset_spam_ham.csv` dentro de la carpeta `data/` (o ajusta la ruta en el script).
2. Ejecuta el script principal:
   ```bash
   python ArbolDecisionLeny.py
   ```
3. El script realiza **50 ejecuciones** con *train/test split* estratificado, entrena un `DecisionTreeClassifier` y genera **tres gr√°ficos**:
   - Accuracy por ejecuci√≥n
   - F1-score por ejecuci√≥n
   - Z-scores (Accuracy y F1 normalizados)
   
   Adem√°s, imprime en consola un **resumen num√©rico** con media y desviaci√≥n est√°ndar de las m√©tricas.

## Dataset (campos t√≠picos)
El dataset incluye caracter√≠sticas de correo como: longitud del mensaje, n√∫mero de enlaces/adjuntos, porcentaje de may√∫sculas, presencia de HTML, remitente conocido, pa√≠s de origen (codificado *one-hot*), entre otras. Las etiquetas se transforman a binario (`spam=1`, `ham=0`).

## Resultados de referencia
En pruebas documentadas, se observaron resultados promedio cercanos a:
- **Accuracy** ‚âà 0.9355
- **F1-score** ‚âà 0.9503

> Estos valores son **de referencia** y variar√°n seg√∫n el dataset y la semilla/partici√≥n de entrenamiento.

## Detalles del pipeline
- Limpieza/normalizaci√≥n de etiqueta (`spam/ham` ‚Üí binario).
- Codificaci√≥n *one-hot* para variables categ√≥ricas (`PaisOrigen`, etc.).
- 50 corridas independientes con `train_test_split(..., stratify=y)`.
- Entrenamiento con `DecisionTreeClassifier` (una semilla distinta por corrida).
- C√°lculo de m√©tricas `accuracy` y `f1`; normalizaci√≥n mediante `scipy.stats.zscore`.
- Visualizaci√≥n con `matplotlib` (3 figuras).
- Resumen final con **medias** y **desviaciones est√°ndar** de las m√©tricas.


## üë§ Autor√≠a
Trabajo/documentaci√≥n por **Leny Santiago L√≥pez Cruz** (ver informe adjunto en el repositorio si aplica).
